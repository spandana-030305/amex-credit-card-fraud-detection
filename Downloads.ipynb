{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d0b0a7b-a09d-48c9-b2d1-40e810f1f127",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests) (2020.6.20)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72ba8c2f-6440-4ccd-892a-5938250d2be8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è  Downloading train_data.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6827MB [00:51, 131.32MB/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Downloaded train_data.csv. Extracting...\n",
      "üßπ Cleaned up train_data.csv.zip\n",
      "‚¨áÔ∏è  Downloading train_labels.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17MB [00:00, 146.02MB/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Downloaded train_labels.csv. Extracting...\n",
      "üßπ Cleaned up train_labels.csv.zip\n",
      "‚¨áÔ∏è  Downloading sample_submission.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33MB [00:00, 159.46MB/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Downloaded sample_submission.csv. Extracting...\n",
      "üßπ Cleaned up sample_submission.csv.zip\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Where to save data\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Load your Kaggle credentials\n",
    "#with open(Path.home() / \".kaggle/kaggle.json\") as f:\n",
    "    #creds = json.load(f)\n",
    "\n",
    "KAGGLE_USERNAME = \"saispandanachalasani\"\n",
    "KAGGLE_KEY = \"b86bbf09f7b12aee5ca32b1eb69198f8\"\n",
    "\n",
    "def download_file(file_name):\n",
    "    url = f\"https://www.kaggle.com/api/v1/competitions/data/download/amex-default-prediction/{file_name}\"\n",
    "    auth = (KAGGLE_USERNAME, KAGGLE_KEY)\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    zip_path = DATA_DIR / f\"{file_name}.zip\"\n",
    "\n",
    "    print(f\"‚¨áÔ∏è  Downloading {file_name}...\")\n",
    "\n",
    "    with requests.get(url, stream=True, auth=auth, headers=headers) as r:\n",
    "        r.raise_for_status()\n",
    "        total_size = int(r.headers.get(\"content-length\", 0))\n",
    "        with open(zip_path, \"wb\") as f:\n",
    "            for chunk in tqdm(r.iter_content(chunk_size=1024 * 1024),  # 1MB chunks\n",
    "                              total=total_size // (1024 * 1024),\n",
    "                              unit=\"MB\"):\n",
    "                f.write(chunk)\n",
    "\n",
    "    print(f\"‚úÖ Downloaded {file_name}. Extracting...\")\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(DATA_DIR)\n",
    "\n",
    "    os.remove(zip_path)\n",
    "    print(f\"üßπ Cleaned up {file_name}.zip\")\n",
    "\n",
    "# Files to grab\n",
    "files = [\"train_data.csv\", \"train_labels.csv\", \"sample_submission.csv\"]\n",
    "for f in files:\n",
    "    download_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9771435c-0412-4dd8-b78e-9a2701846dcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16G\tdata/train_data.csv\n"
     ]
    }
   ],
   "source": [
    "!du -sh data/train_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3cdff30-c8db-411c-943f-78076f1f846a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done! final_dataset.parquet saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "input_file = \"data/train_data.csv\"\n",
    "chunksize = 200_000  # adjust based on RAM\n",
    "\n",
    "writer = None\n",
    "\n",
    "for chunk in pd.read_csv(input_file, chunksize=chunksize):\n",
    "    # Reduce precision\n",
    "    for col in chunk.select_dtypes(include=['float64']).columns:\n",
    "        chunk[col] = chunk[col].astype('float32')\n",
    "    for col in chunk.select_dtypes(include=['int64']).columns:\n",
    "        chunk[col] = chunk[col].astype('int32')\n",
    "\n",
    "    # Convert to Arrow table\n",
    "    table = pa.Table.from_pandas(chunk)\n",
    "\n",
    "    # Write in append mode\n",
    "    if writer is None:\n",
    "        writer = pq.ParquetWriter(\"final_dataset.parquet\", table.schema, compression=\"zstd\")\n",
    "    writer.write_table(table)\n",
    "\n",
    "if writer:\n",
    "    writer.close()\n",
    "\n",
    "print(\"‚úÖ Done! final_dataset.parquet saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5332628c-36c6-47f6-a83e-2dedc6f4f5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
